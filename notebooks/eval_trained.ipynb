{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dc29770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# change to upper dir to use all custom libs (won't be needed if run from main scripts)\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4164845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yadisk\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv(dotenv.find_dotenv())\n",
    "client = yadisk.Client(token=os.environ[\"YA_DISK_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f72bff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scripts.helpers.yadisk_manager import download_model\n",
    "\n",
    "# download_model(\n",
    "#     client=client,\n",
    "#     experiment=\"/bs-diploma/experiments/kaggle/ru-mhr.both_direction.mari-parallel.nllb.upd_tokenizer.finally_fixed\",\n",
    "#     folder='models',\n",
    "#     checkpoint='final',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb97706f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cutefluffyfox\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from scripts.helpers.model_manager import NLLB200Model\n",
    "\n",
    "model = NLLB200Model.from_folder(\n",
    "    model_path='models/model', \n",
    "    tokenizer_path='models/tokenizer', \n",
    "    convert_to_float16=True, \n",
    "    device='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a892278e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Черт товарищ, а тебе-то что делают?', 'Шӱметный йолташ, тыйын пашажат кузе?')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mhr_text = model.translate_single('Как твои дела, дорогой друг?', 'ru', 'mhr')\n",
    "rus_text = model.translate_single(mhr_text, 'mhr', 'ru')\n",
    "rus_text, mhr_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "184c9d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [06:07<00:00,  2.94s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [05:12<00:00,  2.50s/it]\n"
     ]
    }
   ],
   "source": [
    "from scripts.benchmark.flores_dev import benchmark\n",
    "\n",
    "benchmark(model, 'ru-mhr')\n",
    "benchmark(model, 'mhr-ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "054c300a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\cutefluffyfox\\.cache\\huggingface\\modules\\evaluate_modules\\metrics\\evaluate-metric--bleu\\9e0985c1200e367cce45605ce0ecb5ede079894e0f24f54613fca08eeb8aff76 (last modified on Tue Nov  5 05:51:14 2024) since it couldn't be found locally at evaluate-metric--bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from C:\\Users\\cutefluffyfox\\.cache\\huggingface\\modules\\evaluate_modules\\metrics\\evaluate-metric--chrf\\d244bab9383988714085a8dacc4871986d9f025398581c33d6b2ee22836b4069 (last modified on Tue Nov  5 05:54:58 2024) since it couldn't be found locally at evaluate-metric--chrf, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "from scripts.helpers.metric_manager import BLEU, BLEURT, BertScore, CHRF, GoogleBLEU\n",
    "\n",
    "metrics = [\n",
    "    BLEU(),\n",
    "#     BLEURT(),\n",
    "#     BertScore(),\n",
    "    CHRF(),\n",
    "#     GoogleBLEU()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ec8f586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== C:\\Users\\cutefluffyfox\\PycharmProjects\\MT-vocab-tuning\\data\\benchmark\\ru-mhr\\mhr_both_dir_simple.ru_mhr.txt ==========\n",
      "bleu : 0.07319940181732666\n",
      "chrf : 38.2987734504991\n",
      "========== C:\\Users\\cutefluffyfox\\PycharmProjects\\MT-vocab-tuning\\data\\benchmark\\mhr-ru\\mhr_both_dir_simple.mhr_ru.txt ==========\n",
      "bleu : 0.08968501201433417\n",
      "chrf : 36.77403867823899\n",
      "========== C:\\Users\\cutefluffyfox\\PycharmProjects\\MT-vocab-tuning\\data\\benchmark\\mhr-ru\\madlad400.mhr_ru.txt ==========\n",
      "bleu : 0.14416953753714376\n",
      "chrf : 38.20947588930588\n",
      "========== C:\\Users\\cutefluffyfox\\PycharmProjects\\MT-vocab-tuning\\data\\benchmark\\ru-mhr\\madlad400.ru_mhr.txt ==========\n",
      "bleu : 0.021880696091946265\n",
      "chrf : 19.71051192504408\n",
      "========== C:\\Users\\cutefluffyfox\\PycharmProjects\\MT-vocab-tuning\\data\\benchmark\\mhr-ru\\nllb200.mhr_ru.txt ==========\n",
      "bleu : 0.03707498445596439\n",
      "chrf : 27.610867511783933\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scripts.helpers.path_manager import DataManager\n",
    "\n",
    "\n",
    "\n",
    "dm = DataManager()\n",
    "translations = [\n",
    "    dm.get_path('benchmark', 'ru-mhr', 'mhr_both_dir_simple.ru_mhr.txt'),\n",
    "    dm.get_path('benchmark', 'mhr-ru', 'mhr_both_dir_simple.mhr_ru.txt'),\n",
    "    \n",
    "    dm.get_path('benchmark', 'mhr-ru', 'madlad400.mhr_ru.txt'),\n",
    "    dm.get_path('benchmark', 'ru-mhr', 'madlad400.ru_mhr.txt'),\n",
    "#     dm.get_path('benchmark', 'tat-ru', 'madlad400.tat_mhrru.txt'),\n",
    "#     dm.get_path('benchmark', 'ru-tat', 'madlad400.ru_tat.txt'),\n",
    "#     dm.get_path('benchmark', 'kaz-ru', 'madlad400.kaz_ru.txt'),\n",
    "#     dm.get_path('benchmark', 'ru-kaz', 'madlad400.ru_kaz.txt'),\n",
    "    \n",
    "    dm.get_path('benchmark', 'mhr-ru', 'nllb200.mhr_ru.txt'),\n",
    "#     dm.get_path('benchmark', 'tat-ru', 'nllb200.tat_ru.txt'),\n",
    "#     dm.get_path('benchmark', 'ru-tat', 'nllb200.ru_tat.txt'),\n",
    "#     dm.get_path('benchmark', 'kaz-ru', 'nllb200.kaz_ru.txt'),\n",
    "#     dm.get_path('benchmark', 'ru-kaz', 'nllb200.ru_kaz.txt'),\n",
    "]\n",
    "\n",
    "for trans in translations:\n",
    "    print('==========', trans, '==========')\n",
    "    src_lang, dst_lang = trans.split('.')[-2].split('_')\n",
    "    for metric in metrics:\n",
    "        with open(trans, 'r', encoding='UTF-8') as file:\n",
    "            res = [eval(line.strip()) for line in file.readlines()]\n",
    "        df = pd.DataFrame(res)\n",
    "        res_trans, res_ref = df['translation'].to_list(), df[dst_lang].to_list()\n",
    "\n",
    "        print(metric.metric_name, ':', metric(\n",
    "            sources=None,\n",
    "            targets=res_ref,\n",
    "            translations=res_trans,\n",
    "            lang=dst_lang\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092f172e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2842895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
