{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dc29770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# change to upper dir to use all custom libs (won't be needed if run from main scripts)\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4164845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yadisk\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv(dotenv.find_dotenv())\n",
    "client = yadisk.Client(token=os.environ[\"YA_DISK_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f72bff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.helpers.yadisk_manager import download_model\n",
    "\n",
    "\n",
    "experiments = {\n",
    "    # a minor problem with <2lang> token where language group was not passed correctly and initial token == <unk>\n",
    "    'nllb.ru-mhr.both_direction.upd_tokenizer': \"/bs-diploma/experiments/kaggle/ru-mhr.both_direction.mari-parallel.nllb.upd_tokenizer.finally_fixed\",\n",
    "    'nllb.ru-mht.both_direction.old_tokenizer': '/bs-diploma/experiments/kaggle/ru-mhr.both_directions.mari-parallel.nllb.no_upd_tokenizer',\n",
    "    'nllb.ru-mhr.both_direction.upd_tokenizer': \"/bs-diploma/experiments/kaggle/ru-mhr.both_directions.mari-parallel-413k.nllb.no_upd_tokenizer.mhr_fixed\",\n",
    "    'nllb.ru-mhr.sing_direction.upd_tokenizer': \"/bs-diploma/experiments/kaggle/ru-mhr.single_direction.mari-parallel-413k.nllb.update_tokenizer\",\n",
    "    \n",
    "    \n",
    "    # TODO: rename to upd_tokenizer on ya.disk\n",
    "    'nllb.ru-tat.both_direction.upd_tokenizer': '/bs-diploma/experiments/kaggle/ru-tat.both_directions.ipsan.tatar-parallel-400k.nllb.no_upd_tokenizer',\n",
    "    'nllb.ru-tat.both_direction.old_tokenizer': '/bs-diploma/experiments/kaggle/ru-tt.both_direction.ipsan.nllb.base_tokenizer',\n",
    "#     'nllb.ru-tat.sing_direction.old_tokenizer': '',  # TODO: add\n",
    "#     'nllb.tat-ru.sing_direction.old_tokenizer': '',  # TODO: add\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "# download_model(\n",
    "#     client=client,\n",
    "#     experiment=experiments['nllb.ru-tat.both_direction.upd_tokenizer'],\n",
    "#     folder='models',\n",
    "#     checkpoint='last',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb97706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.helpers.model_manager import NLLB200Model\n",
    "\n",
    "# model = NLLB200Model.from_folder(\n",
    "#     model_path='models/model', \n",
    "#     tokenizer_path='models/tokenizer', \n",
    "#     convert_to_float16=True, \n",
    "#     device='auto'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a892278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trn_text = model.translate_single('Как твои дела, дорогой друг?', 'ru', 'tt')\n",
    "# rus_text = model.translate_single(trn_text, 'tt', 'ru')\n",
    "# rus_text, trn_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "184c9d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scripts.benchmark.flores_dev import benchmark\n",
    "\n",
    "# benchmark(model, 'ru-tat')\n",
    "# benchmark(model, 'tat-ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "054c300a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\cutefluffyfox\\.cache\\huggingface\\modules\\evaluate_modules\\metrics\\evaluate-metric--bleu\\9e0985c1200e367cce45605ce0ecb5ede079894e0f24f54613fca08eeb8aff76 (last modified on Tue Nov  5 05:51:14 2024) since it couldn't be found locally at evaluate-metric--bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from C:\\Users\\cutefluffyfox\\.cache\\huggingface\\modules\\evaluate_modules\\metrics\\evaluate-metric--chrf\\d244bab9383988714085a8dacc4871986d9f025398581c33d6b2ee22836b4069 (last modified on Tue Nov  5 05:54:58 2024) since it couldn't be found locally at evaluate-metric--chrf, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "from scripts.helpers.metric_manager import BLEU, BLEURT, BertScore, CHRF, GoogleBLEU, FluencyRU\n",
    "\n",
    "metrics = [\n",
    "    BLEU(),\n",
    "#     BLEURT(),\n",
    "#     BertScore(),\n",
    "    CHRF(),\n",
    "#     FluencyRU(),\n",
    "#     GoogleBLEU()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ec8f586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== \\mhr-ru\\mhr_both_dir_simple.mhr_ru.last.txt ==========\n",
      "bleu : 0.08968501201433417\n",
      "chrf : 36.77403867823899\n",
      "========== \\mhr-ru\\mhr_both_dir_simple.mhr_ru.7200.txt ==========\n",
      "bleu : 0.12787250706142736\n",
      "chrf : 43.42382341215098\n",
      "========== \\mhr-ru\\mhr_both_dir.old_tokenizer.mhr_ru.last.txt ==========\n",
      "bleu : 0.009983102617198474\n",
      "chrf : 16.366378658826093\n",
      "========== \\mhr-ru\\nllb200.mhr_ru.txt ==========\n",
      "bleu : 0.03707498445596439\n",
      "chrf : 27.610867511783933\n",
      "========== \\mhr-ru\\madlad400.mhr_ru.txt ==========\n",
      "bleu : 0.14416953753714376\n",
      "chrf : 38.20947588930588\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scripts.helpers.path_manager import DataManager\n",
    "\n",
    "\n",
    "\n",
    "dm = DataManager()\n",
    "translations = [\n",
    "    dm.get_path('benchmark', 'mhr-ru', 'mhr_both_dir_simple.mhr_ru.last.txt'),\n",
    "    dm.get_path('benchmark', 'mhr-ru', 'mhr_both_dir_simple.mhr_ru.7200.txt'),\n",
    "    dm.get_path('benchmark', 'mhr-ru', 'mhr_both_dir.old_tokenizer.mhr_ru.last.txt'),\n",
    "    dm.get_path('benchmark', 'mhr-ru', 'nllb200.mhr_ru.txt'),\n",
    "    dm.get_path('benchmark', 'mhr-ru', 'madlad400.mhr_ru.txt'),\n",
    "\n",
    "    \n",
    "#     dm.get_path('benchmark', 'ru-mhr', 'mhr_both_dir_simple.ru_mhr.last.txt'),\n",
    "#     dm.get_path('benchmark', 'ru-mhr', 'mhr_both_dir_simple.ru_mhr.7200.txt'),\n",
    "#     dm.get_path('benchmark', 'ru-mhr', 'mhr_both_dir.old_tokenizer.ru_mhr.last.txt'),\n",
    "#     dm.get_path('benchmark', 'ru-mhr', 'mhr_both_dir_simple.ru_mhr.last.txt'),\n",
    "#     dm.get_path('benchmark', 'ru-mhr', 'mhr_both_dir_simple.ru_mhr.7200.txt'),\n",
    "#     dm.get_path('benchmark', 'ru-mhr', 'madlad400.ru_mhr.txt'),\n",
    "\n",
    "    \n",
    "#     dm.get_path('benchmark', 'tat-ru', 'tat_both_dir.no_token_upd.tat_ru.last.txt'),\n",
    "#     dm.get_path('benchmark', 'tat-ru', 'tat_both_dir.token_upd.tat_ru.last.txt'),\n",
    "#     dm.get_path('benchmark', 'tat-ru', 'madlad400.tat_ru.txt'),\n",
    "#     dm.get_path('benchmark', 'tat-ru', 'nllb200.tat_ru.txt'),\n",
    "\n",
    "#     dm.get_path('benchmark', 'ru-tat', 'tat_both_dir.no_token_upd.ru_tat.last.txt'),\n",
    "#     dm.get_path('benchmark', 'ru-tat', 'tat_both_dir.token_upd.ru_tat.last.txt'),\n",
    "#     dm.get_path('benchmark', 'ru-tat', 'nllb200.ru_tat.txt'),\n",
    "#     dm.get_path('benchmark', 'ru-tat', 'madlad400.ru_tat.txt'),\n",
    "\n",
    "    \n",
    "#     dm.get_path('benchmark', 'kaz-ru', 'madlad400.kaz_ru.txt'),\n",
    "#     dm.get_path('benchmark', 'ru-kaz', 'madlad400.ru_kaz.txt'),\n",
    "    \n",
    "#     dm.get_path('benchmark', 'kaz-ru', 'nllb200.kaz_ru.txt'),\n",
    "#     dm.get_path('benchmark', 'ru-kaz', 'nllb200.ru_kaz.txt'),\n",
    "]\n",
    "\n",
    "for trans in translations:\n",
    "    print('==========', trans.split('benchmark')[-1], '==========')\n",
    "    direction = trans.split('benchmark')[-1].replace('\\\\', '/').strip('/').split('/')[0]\n",
    "    src_lang, dst_lang = direction.split('-')\n",
    "    for metric in metrics:\n",
    "        if not metric.lang_is_supported(metric):\n",
    "            continue\n",
    "        \n",
    "        with open(trans, 'r', encoding='UTF-8') as file:\n",
    "            res = [eval(line.strip()) for line in file.readlines()]\n",
    "        df = pd.DataFrame(res)\n",
    "        if dst_lang == 'ru' and 'ru' not in df.columns and 'rus' in df.columns:\n",
    "            dst_lang = 'rus'\n",
    "        res_trans, res_ref = df['translation'].to_list(), df[dst_lang].to_list()\n",
    "\n",
    "        print(metric.metric_name, ':', metric(\n",
    "            sources=None,\n",
    "            targets=res_ref,\n",
    "            translations=res_trans,\n",
    "            lang=dst_lang\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "092f172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\cutefluffyfox\\\\PycharmProjects\\\\MT-vocab-tuning\\\\data\\\\benchmark\\\\mhr-ru\\\\nllb200.mhr_ru.txt', 'r', encoding='UTF-8') as file:\n",
    "    print(eval(file.readlines()[942])['translation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2842895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
